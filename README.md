# Intermediate Language Choice in Chat-related Tasks 

The purpose of this work is to study the influence of the choice of an intermediate language on the performance of models in dialog tasks. To achieve this goal, we set ourselves the following tasks:  

1. To analyze and compare various methods of translating dialog data into an intermediate language.  
2. To study the effect of an intermediate language on the performance of various machine learning model architectures, such as **FastText**, **mT5-large**, **mT5-base**, **BERT**, **XLM-RoBERTa** and **BLOOM**.  
3. Evaluate the stability of multilingual models in different translations.  

The results of the current work can be presented in the image below:  

![Training results](https://drive.google.com/uc?export=view&id=14kigA2_RlgLrjrR2Ox32c6r_8quD7wCx)

---
Please, feel free to contact to me:  
Telegram: [@travelwithtagir](https://t.me/travelwithtagir/)  
Data Blog: [@tagir_analyzes](https://t.me/tagir_analyzes/)  
E-mail: tagir@photographer.net  
LinkedIn: [Tagir Khairutdinov](https://linkedin.com/in/tagir-data-analyst/)  
